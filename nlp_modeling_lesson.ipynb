{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16df3f0b",
   "metadata": {},
   "source": [
    "# NLP Modeling Lesson\n",
    "\n",
    "In this lesson, we'll do a bit of feature engineering, and then model our text data. We'll be aiming to predict whether a given text message is spam or not, and trying to predict the category of news articles.\n",
    "\n",
    "## Feature Extraction: TF-IDF\n",
    "- **TF**: Term Frequency; how often a particular word appears in a document. \n",
    "\n",
    "        \"apple\" appears in this document 15 times\n",
    "- **IDF**: Inverse Document Frequency; a measure of how many (related) documents contain a particular word. \n",
    "\n",
    "        \"apple\" is found in 10 of the 58 documents in our sample\n",
    "        \n",
    "- **TF-IDF**: A combination of the two measures above.\n",
    "\n",
    "### TF: Term Frequency\n",
    "\n",
    "Term frequency can be calculated in a number of ways, all of which reflect how frequently a word appears in a document.\n",
    "\n",
    "- **Raw Count**: This is simply the count of the number of occurances of each word.\n",
    "- **Frequency**: The number of times each word appears divided by the total number of words.\n",
    "- **Augmented Frequency**: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents.\n",
    "\n",
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28767537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prepare import basic_clean, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c44f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mary\n",
       "1        had\n",
       "2          a\n",
       "3     little\n",
       "4       lamb\n",
       "5          a\n",
       "6     little\n",
       "7       lamb\n",
       "8          a\n",
       "9     little\n",
       "10      lamb\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = 'Mary had a little lamb, a little lamb, a little lamb.'\n",
    "\n",
    "# clean up the text\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459169ce",
   "metadata": {},
   "source": [
    "From the series we can extract the value_counts, which is our raw count for term frequency. Once we have the raw counts, we can calculate the other measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d942b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little    3\n",
       "lamb      3\n",
       "a         3\n",
       "mary      1\n",
       "had       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784ec879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count\n",
       "little          3\n",
       "lamb            3\n",
       "a               3\n",
       "mary            1\n",
       "had             1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby = pd.DataFrame({'raw_count':words.value_counts()})\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9604b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency\n",
       "little          3   0.272727\n",
       "lamb            3   0.272727\n",
       "a               3   0.272727\n",
       "mary            1   0.090909\n",
       "had             1   0.090909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby['frequency'] = lullaby.raw_count.apply(lambda x: x/lullaby.raw_count.sum())\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f496ffd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "little          3   0.272727             1.000000\n",
       "lamb            3   0.272727             1.000000\n",
       "a               3   0.272727             1.000000\n",
       "mary            1   0.090909             0.333333\n",
       "had             1   0.090909             0.333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lullaby['augmented_frequency'] = lullaby.frequency.apply(lambda x: x/lullaby.frequency.max())\n",
    "lullaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3000d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamb</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "little          3   0.272727             1.000000\n",
       "lamb            3   0.272727             1.000000\n",
       "a               3   0.272727             1.000000\n",
       "mary            1   0.090909             0.333333\n",
       "had             1   0.090909             0.333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can accomplish the same task using fewer lines of code using .assign\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fba147",
   "metadata": {},
   "source": [
    "**Takeaways**: These are simply numeric representations of one characteristic of the strings in our corpus (frequency). Aside from simply showing us that some words are more frequent than others, this information by itself doesn't provide us much value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdebed",
   "metadata": {},
   "source": [
    "## IDF: Inverse Document Frequency\n",
    "\n",
    "Inverse Document Frequency also provides information about individual words, but, in order to use this measure, we must have multiple documents, i.e. several different bodies of text.\n",
    "\n",
    "Inverse Document Frequency tells us how much **information** a word provides. It is based on how commonly a word appears across multiple documents. The metric is divised such that the more frequently a word appears, the lower the IDF for that word will be.\n",
    "\n",
    "      idf(word) = log(# of documents / # of documents containing word)\n",
    "      \n",
    "> If a given word doesn't appear in any documents, the denominator in the equation above would be zero, so some definitions of idf will add 1 to the denominator.\n",
    "\n",
    "For example, imagine we have 20 documents. We can visualize what the idf score looks like with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac7bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'IDF for a given word')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_documents = 20\n",
    "\n",
    "x = np.arange(1, n_documents + 1)\n",
    "y = np.log(n_documents / x)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, y, marker='.')\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.xlabel('# of Documents the word appears in')\n",
    "plt.ylabel('IDF')\n",
    "plt.title('IDF for a given word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035fe18",
   "metadata": {},
   "source": [
    "**Takeaways**: Suppose you are trying to create a model that predicts whether a given corpus is written before 1900 or after 1900. If a word appears in every document of your sample, its not going to provide much insight. But if a word only appears in a small number of documents, then it could be representative of an underlying trend (i.e. \"afternoonified\" shows up in a small number of documents all of which were written before 1900).\n",
    "\n",
    "    High IDF = More information\n",
    "\n",
    "Let's look at an example of calculating IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885eb660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Codeup's data science program was created in response to a \"\n",
      "            'percieved lack of data science talent, and growing demand.',\n",
      " 'description': \"Codeup's data science program teaches hands on skills using \"\n",
      "                'Python and pandas.',\n",
      " 'news': 'Codeup announced last thursday that they just launched a new data '\n",
      "         'science program. It is 18 weeks long.'}\n",
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n",
      "{'context': 'codeups data science program wa created in response to a '\n",
      "            'percieved lack of data science talent and growing demand',\n",
      " 'description': 'codeups data science program teach hand on skill using python '\n",
      "                'and panda',\n",
      " 'news': 'codeup announced last thursday that they just launched a new data '\n",
      "         'science program it is 18 week long'}\n"
     ]
    }
   ],
   "source": [
    "# our 3 example documents\n",
    "documents = {\n",
    "    'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
    "    'description': 'Codeup\\'s data science program teaches hands on skills using Python and pandas.',\n",
    "    'context': 'Codeup\\'s data science program was created in response to a percieved lack of data science talent, and growing demand.'\n",
    "}\n",
    "pprint(documents)\n",
    "\n",
    "print('\\nCleaning and lemmatizing...\\n')\n",
    "\n",
    "documents = {topic: lemmatize(basic_clean(documents[topic])) for topic in documents}\n",
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ebbd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['codeup announced last thursday that they just launched a new data science program it is 18 week long', 'codeups data science program teach hand on skill using python and panda', 'codeups data science program wa created in response to a percieved lack of data science talent and growing demand'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize document values to help explain our upcoming idf function\n",
    "documents.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a39369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word):\n",
    "    '''A simple way to calculate idf for demonstration. Note that this \n",
    "    function relies on a globally defined documents variable.'''\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c13182e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['codeup', 'announced', 'last', 'thursday', 'that', 'they', 'just',\n",
       "       'launched', 'a', 'new', 'data', 'science', 'program', 'it', 'is',\n",
       "       '18', 'week', 'long', 'codeups', 'teach', 'hand', 'on', 'skill',\n",
       "       'using', 'python', 'and', 'panda', 'wa', 'created', 'in',\n",
       "       'response', 'to', 'percieved', 'lack', 'of', 'talent', 'growing',\n",
       "       'demand'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd928fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panda</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percieved</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lack</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talent</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growing</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announced</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thursday</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeups</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codeup</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf\n",
       "word          \n",
       "teach      3.0\n",
       "created    3.0\n",
       "hand       3.0\n",
       "skill      3.0\n",
       "using      3.0\n",
       "python     3.0\n",
       "panda      3.0\n",
       "wa         3.0\n",
       "response   3.0\n",
       "long       3.0\n",
       "to         3.0\n",
       "percieved  3.0\n",
       "lack       3.0\n",
       "of         3.0\n",
       "talent     3.0\n",
       "growing    3.0\n",
       "announced  3.0\n",
       "demand     3.0\n",
       "new        3.0\n",
       "launched   3.0\n",
       "18         3.0\n",
       "last       3.0\n",
       "is         3.0\n",
       "it         3.0\n",
       "thursday   3.0\n",
       "that       3.0\n",
       "they       3.0\n",
       "just       3.0\n",
       "week       3.0\n",
       "codeups    1.5\n",
       "in         1.5\n",
       "and        1.5\n",
       "a          1.0\n",
       "data       1.0\n",
       "science    1.0\n",
       "program    1.0\n",
       "on         1.0\n",
       "codeup     1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23001665",
   "metadata": {},
   "source": [
    "**Takeaways**: Words with the lowest IDF score were found in every document. They do us no good in helping us to distinguish whether a given corpus was \"context\", \"description\", or \"news\". Words with high IDF scores are more strongly linked to a particular classification. \n",
    "\n",
    "But this sample is so small that we should be cautious in using the word \"on\" as a means to classify a future corpus. \n",
    "\n",
    "> The calculation for an individual IDF score requires a word **and** a set of documents.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "TF-IDF is simply the multiplication of the two metrics we've discussed above. Let's calculate an TF-IDF for all of the words and documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5bd75de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('news', 'codeup announced last thursday that they just launched a new data science program it is 18 week long'), ('description', 'codeups data science program teach hand on skill using python and panda'), ('context', 'codeups data science program wa created in response to a percieved lack of data science talent and growing demand')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create an empty list to store values for us as we iterate through our data\n",
    "tfs = []\n",
    "\n",
    "# Start by iterating over all the documents. We can use .items() to speed up our loop:\n",
    "documents.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc91974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop\n",
    "for doc, text in documents.items():\n",
    "    # We will make a dataframe that contains the term frequency for every word\n",
    "    df = (pd.Series(text.split())\n",
    "          .value_counts()\n",
    "          .reset_index()\n",
    "          .set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "          .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "          .drop(columns='raw_count')\n",
    "          .assign(doc=doc))\n",
    "    # Then add that data frame to our list\n",
    "    tfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e19375ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING LOOP\n",
      "\n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: news\n",
      "Text: codeup announced last thursday that they just launched a new data science program it is 18 week long\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0        codeup\n",
      "1     announced\n",
      "2          last\n",
      "3      thursday\n",
      "4          that\n",
      "5          they\n",
      "6          just\n",
      "7      launched\n",
      "8             a\n",
      "9           new\n",
      "10         data\n",
      "11      science\n",
      "12      program\n",
      "13           it\n",
      "14           is\n",
      "15           18\n",
      "16         week\n",
      "17         long\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "week         1\n",
      "science      1\n",
      "data         1\n",
      "a            1\n",
      "announced    1\n",
      "they         1\n",
      "codeup       1\n",
      "just         1\n",
      "18           1\n",
      "that         1\n",
      "launched     1\n",
      "new          1\n",
      "program      1\n",
      "last         1\n",
      "is           1\n",
      "it           1\n",
      "thursday     1\n",
      "long         1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "        index  0\n",
      "0        week  1\n",
      "1     science  1\n",
      "2        data  1\n",
      "3           a  1\n",
      "4   announced  1\n",
      "5        they  1\n",
      "6      codeup  1\n",
      "7        just  1\n",
      "8          18  1\n",
      "9        that  1\n",
      "10   launched  1\n",
      "11        new  1\n",
      "12    program  1\n",
      "13       last  1\n",
      "14         is  1\n",
      "15         it  1\n",
      "16   thursday  1\n",
      "17       long  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "         word  raw_count\n",
      "0        week          1\n",
      "1     science          1\n",
      "2        data          1\n",
      "3           a          1\n",
      "4   announced          1\n",
      "5        they          1\n",
      "6      codeup          1\n",
      "7        just          1\n",
      "8          18          1\n",
      "9        that          1\n",
      "10   launched          1\n",
      "11        new          1\n",
      "12    program          1\n",
      "13       last          1\n",
      "14         is          1\n",
      "15         it          1\n",
      "16   thursday          1\n",
      "17       long          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "         word  raw_count        tf\n",
      "0        week          1  0.055556\n",
      "1     science          1  0.055556\n",
      "2        data          1  0.055556\n",
      "3           a          1  0.055556\n",
      "4   announced          1  0.055556\n",
      "5        they          1  0.055556\n",
      "6      codeup          1  0.055556\n",
      "7        just          1  0.055556\n",
      "8          18          1  0.055556\n",
      "9        that          1  0.055556\n",
      "10   launched          1  0.055556\n",
      "11        new          1  0.055556\n",
      "12    program          1  0.055556\n",
      "13       last          1  0.055556\n",
      "14         is          1  0.055556\n",
      "15         it          1  0.055556\n",
      "16   thursday          1  0.055556\n",
      "17       long          1  0.055556\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "         word        tf\n",
      "0        week  0.055556\n",
      "1     science  0.055556\n",
      "2        data  0.055556\n",
      "3           a  0.055556\n",
      "4   announced  0.055556\n",
      "5        they  0.055556\n",
      "6      codeup  0.055556\n",
      "7        just  0.055556\n",
      "8          18  0.055556\n",
      "9        that  0.055556\n",
      "10   launched  0.055556\n",
      "11        new  0.055556\n",
      "12    program  0.055556\n",
      "13       last  0.055556\n",
      "14         is  0.055556\n",
      "15         it  0.055556\n",
      "16   thursday  0.055556\n",
      "17       long  0.055556\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "         word        tf   doc\n",
      "0        week  0.055556  news\n",
      "1     science  0.055556  news\n",
      "2        data  0.055556  news\n",
      "3           a  0.055556  news\n",
      "4   announced  0.055556  news\n",
      "5        they  0.055556  news\n",
      "6      codeup  0.055556  news\n",
      "7        just  0.055556  news\n",
      "8          18  0.055556  news\n",
      "9        that  0.055556  news\n",
      "10   launched  0.055556  news\n",
      "11        new  0.055556  news\n",
      "12    program  0.055556  news\n",
      "13       last  0.055556  news\n",
      "14         is  0.055556  news\n",
      "15         it  0.055556  news\n",
      "16   thursday  0.055556  news\n",
      "17       long  0.055556  news\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: description\n",
      "Text: codeups data science program teach hand on skill using python and panda\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0     codeups\n",
      "1        data\n",
      "2     science\n",
      "3     program\n",
      "4       teach\n",
      "5        hand\n",
      "6          on\n",
      "7       skill\n",
      "8       using\n",
      "9      python\n",
      "10        and\n",
      "11      panda\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "using      1\n",
      "and        1\n",
      "hand       1\n",
      "science    1\n",
      "program    1\n",
      "data       1\n",
      "python     1\n",
      "panda      1\n",
      "skill      1\n",
      "codeups    1\n",
      "teach      1\n",
      "on         1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "      index  0\n",
      "0     using  1\n",
      "1       and  1\n",
      "2      hand  1\n",
      "3   science  1\n",
      "4   program  1\n",
      "5      data  1\n",
      "6    python  1\n",
      "7     panda  1\n",
      "8     skill  1\n",
      "9   codeups  1\n",
      "10    teach  1\n",
      "11       on  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "       word  raw_count\n",
      "0     using          1\n",
      "1       and          1\n",
      "2      hand          1\n",
      "3   science          1\n",
      "4   program          1\n",
      "5      data          1\n",
      "6    python          1\n",
      "7     panda          1\n",
      "8     skill          1\n",
      "9   codeups          1\n",
      "10    teach          1\n",
      "11       on          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "       word  raw_count        tf\n",
      "0     using          1  0.083333\n",
      "1       and          1  0.083333\n",
      "2      hand          1  0.083333\n",
      "3   science          1  0.083333\n",
      "4   program          1  0.083333\n",
      "5      data          1  0.083333\n",
      "6    python          1  0.083333\n",
      "7     panda          1  0.083333\n",
      "8     skill          1  0.083333\n",
      "9   codeups          1  0.083333\n",
      "10    teach          1  0.083333\n",
      "11       on          1  0.083333\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "       word        tf\n",
      "0     using  0.083333\n",
      "1       and  0.083333\n",
      "2      hand  0.083333\n",
      "3   science  0.083333\n",
      "4   program  0.083333\n",
      "5      data  0.083333\n",
      "6    python  0.083333\n",
      "7     panda  0.083333\n",
      "8     skill  0.083333\n",
      "9   codeups  0.083333\n",
      "10    teach  0.083333\n",
      "11       on  0.083333\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "       word        tf          doc\n",
      "0     using  0.083333  description\n",
      "1       and  0.083333  description\n",
      "2      hand  0.083333  description\n",
      "3   science  0.083333  description\n",
      "4   program  0.083333  description\n",
      "5      data  0.083333  description\n",
      "6    python  0.083333  description\n",
      "7     panda  0.083333  description\n",
      "8     skill  0.083333  description\n",
      "9   codeups  0.083333  description\n",
      "10    teach  0.083333  description\n",
      "11       on  0.083333  description\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n",
      "Text being manipulated:\n",
      "-----------------------------------------\n",
      "Document: context\n",
      "Text: codeups data science program wa created in response to a percieved lack of data science talent and growing demand\n",
      "\n",
      "\n",
      "Step 1: Splitting the corpus into a list of words\n",
      "df = (pd.Series(text.split()))\n",
      "-----------------------------------------\n",
      "0       codeups\n",
      "1          data\n",
      "2       science\n",
      "3       program\n",
      "4            wa\n",
      "5       created\n",
      "6            in\n",
      "7      response\n",
      "8            to\n",
      "9             a\n",
      "10    percieved\n",
      "11         lack\n",
      "12           of\n",
      "13         data\n",
      "14      science\n",
      "15       talent\n",
      "16          and\n",
      "17      growing\n",
      "18       demand\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Step 2: Converting list of words into a value count array\n",
      "df = df.value_counts()\n",
      "-----------------------------------------\n",
      "science      2\n",
      "data         2\n",
      "response     1\n",
      "growing      1\n",
      "a            1\n",
      "percieved    1\n",
      "lack         1\n",
      "program      1\n",
      "and          1\n",
      "to           1\n",
      "wa           1\n",
      "created      1\n",
      "in           1\n",
      "demand       1\n",
      "of           1\n",
      "talent       1\n",
      "codeups      1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Step 3: Resetting the index\n",
      "df = df.reset_index()\n",
      "-----------------------------------------\n",
      "        index  0\n",
      "0     science  2\n",
      "1        data  2\n",
      "2    response  1\n",
      "3     growing  1\n",
      "4           a  1\n",
      "5   percieved  1\n",
      "6        lack  1\n",
      "7     program  1\n",
      "8         and  1\n",
      "9          to  1\n",
      "10         wa  1\n",
      "11    created  1\n",
      "12         in  1\n",
      "13     demand  1\n",
      "14         of  1\n",
      "15     talent  1\n",
      "16    codeups  1\n",
      "\n",
      "\n",
      "Step 4: Relabeling the columns\n",
      "df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
      "-----------------------------------------\n",
      "         word  raw_count\n",
      "0     science          2\n",
      "1        data          2\n",
      "2    response          1\n",
      "3     growing          1\n",
      "4           a          1\n",
      "5   percieved          1\n",
      "6        lack          1\n",
      "7     program          1\n",
      "8         and          1\n",
      "9          to          1\n",
      "10         wa          1\n",
      "11    created          1\n",
      "12         in          1\n",
      "13     demand          1\n",
      "14         of          1\n",
      "15     talent          1\n",
      "16    codeups          1\n",
      "\n",
      "\n",
      "Step 5: Calculating the Term Frequency of Each Word within this one corpus\n",
      "df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
      "-----------------------------------------\n",
      "         word  raw_count        tf\n",
      "0     science          2  0.117647\n",
      "1        data          2  0.117647\n",
      "2    response          1  0.058824\n",
      "3     growing          1  0.058824\n",
      "4           a          1  0.058824\n",
      "5   percieved          1  0.058824\n",
      "6        lack          1  0.058824\n",
      "7     program          1  0.058824\n",
      "8         and          1  0.058824\n",
      "9          to          1  0.058824\n",
      "10         wa          1  0.058824\n",
      "11    created          1  0.058824\n",
      "12         in          1  0.058824\n",
      "13     demand          1  0.058824\n",
      "14         of          1  0.058824\n",
      "15     talent          1  0.058824\n",
      "16    codeups          1  0.058824\n",
      "\n",
      "\n",
      "Step 6: Dropping the 'raw_count' column\n",
      "df = df.drop(columns='raw_count')\n",
      "-----------------------------------------\n",
      "         word        tf\n",
      "0     science  0.117647\n",
      "1        data  0.117647\n",
      "2    response  0.058824\n",
      "3     growing  0.058824\n",
      "4           a  0.058824\n",
      "5   percieved  0.058824\n",
      "6        lack  0.058824\n",
      "7     program  0.058824\n",
      "8         and  0.058824\n",
      "9          to  0.058824\n",
      "10         wa  0.058824\n",
      "11    created  0.058824\n",
      "12         in  0.058824\n",
      "13     demand  0.058824\n",
      "14         of  0.058824\n",
      "15     talent  0.058824\n",
      "16    codeups  0.058824\n",
      "\n",
      "\n",
      "Step 6: Adding the document label for this corpus\n",
      "df['doc'] = doc\n",
      "-----------------------------------------\n",
      "         word        tf      doc\n",
      "0     science  0.117647  context\n",
      "1        data  0.117647  context\n",
      "2    response  0.058824  context\n",
      "3     growing  0.058824  context\n",
      "4           a  0.058824  context\n",
      "5   percieved  0.058824  context\n",
      "6        lack  0.058824  context\n",
      "7     program  0.058824  context\n",
      "8         and  0.058824  context\n",
      "9          to  0.058824  context\n",
      "10         wa  0.058824  context\n",
      "11    created  0.058824  context\n",
      "12         in  0.058824  context\n",
      "13     demand  0.058824  context\n",
      "14         of  0.058824  context\n",
      "15     talent  0.058824  context\n",
      "16    codeups  0.058824  context\n",
      "\n",
      "\n",
      "ITERATION OF ELEMENT COMPLETE\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What actually happened in that code block? Overexplanation using print statements:\n",
    "print(\"BEGINNING LOOP\")\n",
    "print(\"\\n\")\n",
    "for doc, text in documents.items():\n",
    "    print(\"Text being manipulated:\")\n",
    "    print('-----------------------------------------')\n",
    "    print(f'Document: {doc}')\n",
    "    print(f'Text: {text}')\n",
    "    print('\\n')\n",
    "    print(\"Step 1: Splitting the corpus into a list of words\")\n",
    "    print(\"df = (pd.Series(text.split()))\")\n",
    "    print('-----------------------------------------')\n",
    "    df = (pd.Series(text.split()))\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 2: Converting list of words into a value count array\")\n",
    "    print(\"df = df.value_counts()\")\n",
    "    print('-----------------------------------------')\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 3: Resetting the index\")\n",
    "    print(\"df = df.reset_index()\")\n",
    "    print('-----------------------------------------')\n",
    "    df = df.reset_index()\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 4: Relabeling the columns\")\n",
    "    print(\"df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\")\n",
    "    print('-----------------------------------------')    \n",
    "    df = df.set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "    print(df)\n",
    "    print('\\n')    \n",
    "    \n",
    "    print(\"Step 5: Calculating the Term Frequency of Each Word within this one corpus\")\n",
    "    print(\"df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\")\n",
    "    print('-----------------------------------------')      \n",
    "    df['tf'] = df.raw_count.apply(lambda x: x/df.shape[0])\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Step 6: Dropping the 'raw_count' column\")\n",
    "    print(\"df = df.drop(columns='raw_count')\")\n",
    "    print('-----------------------------------------')      \n",
    "    df = df.drop(columns='raw_count')\n",
    "    print(df)\n",
    "    print('\\n')    \n",
    "    \n",
    "    print(\"Step 6: Adding the document label for this corpus\")\n",
    "    print(\"df['doc'] = doc\")\n",
    "    print('-----------------------------------------') \n",
    "    df['doc'] = doc\n",
    "    print(df)\n",
    "    print('\\n')\n",
    "    print(\"ITERATION OF ELEMENT COMPLETE\")\n",
    "    print('\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2059a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         word        tf   doc\n",
       " 0        week  0.055556  news\n",
       " 1     science  0.055556  news\n",
       " 2        data  0.055556  news\n",
       " 3           a  0.055556  news\n",
       " 4   announced  0.055556  news\n",
       " 5        they  0.055556  news\n",
       " 6      codeup  0.055556  news\n",
       " 7        just  0.055556  news\n",
       " 8          18  0.055556  news\n",
       " 9        that  0.055556  news\n",
       " 10   launched  0.055556  news\n",
       " 11        new  0.055556  news\n",
       " 12    program  0.055556  news\n",
       " 13       last  0.055556  news\n",
       " 14         is  0.055556  news\n",
       " 15         it  0.055556  news\n",
       " 16   thursday  0.055556  news\n",
       " 17       long  0.055556  news,\n",
       "        word        tf          doc\n",
       " 0     using  0.083333  description\n",
       " 1       and  0.083333  description\n",
       " 2      hand  0.083333  description\n",
       " 3   science  0.083333  description\n",
       " 4   program  0.083333  description\n",
       " 5      data  0.083333  description\n",
       " 6    python  0.083333  description\n",
       " 7     panda  0.083333  description\n",
       " 8     skill  0.083333  description\n",
       " 9   codeups  0.083333  description\n",
       " 10    teach  0.083333  description\n",
       " 11       on  0.083333  description,\n",
       "          word        tf      doc\n",
       " 0     science  0.117647  context\n",
       " 1        data  0.117647  context\n",
       " 2    response  0.058824  context\n",
       " 3     growing  0.058824  context\n",
       " 4           a  0.058824  context\n",
       " 5   percieved  0.058824  context\n",
       " 6        lack  0.058824  context\n",
       " 7     program  0.058824  context\n",
       " 8         and  0.058824  context\n",
       " 9          to  0.058824  context\n",
       " 10         wa  0.058824  context\n",
       " 11    created  0.058824  context\n",
       " 12         in  0.058824  context\n",
       " 13     demand  0.058824  context\n",
       " 14         of  0.058824  context\n",
       " 15     talent  0.058824  context\n",
       " 16    codeups  0.058824  context]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "494a7ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teach</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skill</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panda</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hand</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>using</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lack</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>percieved</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>talent</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>of</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>growing</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>response</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>demand</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>to</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wa</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>created</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>week</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thursday</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>launched</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>announced</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>they</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>just</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>it</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>that</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>new</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>last</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>is</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>long</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>codeups</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>science</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>in</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>and</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>codeups</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>on</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>program</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>science</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>a</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>program</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>science</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>program</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>codeup</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word          doc    tf_idf\n",
       "0       teach  description  0.250000\n",
       "1       skill  description  0.250000\n",
       "2       panda  description  0.250000\n",
       "3      python  description  0.250000\n",
       "4        hand  description  0.250000\n",
       "5       using  description  0.250000\n",
       "6        lack      context  0.176471\n",
       "7   percieved      context  0.176471\n",
       "8      talent      context  0.176471\n",
       "9          of      context  0.176471\n",
       "10    growing      context  0.176471\n",
       "11   response      context  0.176471\n",
       "12     demand      context  0.176471\n",
       "13         to      context  0.176471\n",
       "14         wa      context  0.176471\n",
       "15    created      context  0.176471\n",
       "16       week         news  0.166667\n",
       "17   thursday         news  0.166667\n",
       "18   launched         news  0.166667\n",
       "19  announced         news  0.166667\n",
       "20       they         news  0.166667\n",
       "21       just         news  0.166667\n",
       "22         it         news  0.166667\n",
       "23       that         news  0.166667\n",
       "24         18         news  0.166667\n",
       "25        new         news  0.166667\n",
       "26       last         news  0.166667\n",
       "27         is         news  0.166667\n",
       "28       long         news  0.166667\n",
       "29    codeups  description  0.125000\n",
       "30        and  description  0.125000\n",
       "31    science      context  0.117647\n",
       "32       data      context  0.117647\n",
       "33         in      context  0.088235\n",
       "34        and      context  0.088235\n",
       "35    codeups      context  0.088235\n",
       "36         on  description  0.083333\n",
       "37    program  description  0.083333\n",
       "38    science  description  0.083333\n",
       "39       data  description  0.083333\n",
       "40          a      context  0.058824\n",
       "41    program      context  0.058824\n",
       "42    science         news  0.055556\n",
       "43    program         news  0.055556\n",
       "44     codeup         news  0.055556\n",
       "45          a         news  0.055556\n",
       "46       data         news  0.055556"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a945e1b",
   "metadata": {},
   "source": [
    "It's more common to see the data presented with the words as features, and the documents as observations, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5352734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF for each word/doc combination\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>18</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeups</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word               18         a       and  announced    codeup   codeups  \\\n",
       "doc                                                                        \n",
       "context      0.000000  0.058824  0.088235   0.000000  0.000000  0.088235   \n",
       "description  0.000000  0.000000  0.125000   0.000000  0.000000  0.125000   \n",
       "news         0.166667  0.055556  0.000000   0.166667  0.055556  0.000000   \n",
       "\n",
       "word          created      data    demand   growing  ...  skill    talent  \\\n",
       "doc                                                  ...                    \n",
       "context      0.176471  0.117647  0.176471  0.176471  ...   0.00  0.176471   \n",
       "description  0.000000  0.083333  0.000000  0.000000  ...   0.25  0.000000   \n",
       "news         0.000000  0.055556  0.000000  0.000000  ...   0.00  0.000000   \n",
       "\n",
       "word         teach      that      they  thursday        to  using        wa  \\\n",
       "doc                                                                           \n",
       "context       0.00  0.000000  0.000000  0.000000  0.176471   0.00  0.176471   \n",
       "description   0.25  0.000000  0.000000  0.000000  0.000000   0.25  0.000000   \n",
       "news          0.00  0.166667  0.166667  0.166667  0.000000   0.00  0.000000   \n",
       "\n",
       "word             week  \n",
       "doc                    \n",
       "context      0.000000  \n",
       "description  0.000000  \n",
       "news         0.166667  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "print(\"TF-IDF for each word/doc combination\")\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x: x))\n",
    " .fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2dd7a",
   "metadata": {},
   "source": [
    "## TF-IDF with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2061d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x37 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(documents.values())\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c0e1d",
   "metadata": {},
   "source": [
    "We get back a sparse matrix, a matrix with more 0s than anything else. Numpy has a special type that makes some manipulations and operations faster on sparse matrices.\n",
    "\n",
    "Becuase our data set is pretty small, we can convert our sparse matrix to a regular one, and put everything in a dataframe. If our data were larger, the operation below might take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e094dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeups</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>hand</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.250693</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.250693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329631</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.194456</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.194456</td>\n",
       "      <td>0.255686</td>\n",
       "      <td>0.302025</td>\n",
       "      <td>0.255686</td>\n",
       "      <td>0.255686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.255686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255686</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       18       and  announced  codeup   codeups   created      data  \\\n",
       "0  0.2578  0.000000     0.2578  0.2578  0.000000  0.000000  0.152261   \n",
       "1  0.0000  0.250693     0.0000  0.0000  0.250693  0.000000  0.194686   \n",
       "2  0.0000  0.194456     0.0000  0.0000  0.194456  0.255686  0.302025   \n",
       "\n",
       "     demand   growing      hand  ...     skill    talent     teach    that  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.2578   \n",
       "1  0.000000  0.000000  0.329631  ...  0.329631  0.000000  0.329631  0.0000   \n",
       "2  0.255686  0.255686  0.000000  ...  0.000000  0.255686  0.000000  0.0000   \n",
       "\n",
       "     they  thursday        to     using        wa    week  \n",
       "0  0.2578    0.2578  0.000000  0.000000  0.000000  0.2578  \n",
       "1  0.0000    0.0000  0.000000  0.329631  0.000000  0.0000  \n",
       "2  0.0000    0.0000  0.255686  0.000000  0.255686  0.0000  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0762a2",
   "metadata": {},
   "source": [
    "Why are the values different? Because in our manual version we used a simplified formula. Scikit-learn uses the proper IDF formula to calculate TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1f038",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Now we'll use the computed TF-IDF values as features in a model. We'll take a look at the spam data set first.\n",
    "\n",
    "Because of the way we are modeling the data, we have a lot of columns, and it is not uncommon to have more columns than rows. Also, our data is very imbalanced in the class distribution, that is, there are many more ham messages than spam messages.\n",
    "\n",
    "Other than these considerations, we can treat this as a standard classification problem. We'll use logistic regression as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8112d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from env import user, password, host\n",
    "\n",
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "url = get_db_url(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae14f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.49%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3858   111\n",
      "spam          1   487\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.81      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.97      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96c3bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.07%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    50\n",
      "spam         5    99\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.99      0.97       966\n",
      "        spam       0.95      0.66      0.78       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.95      0.83      0.88      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df88b16",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Do your work for this exercise in a file named `model.ipynb`.\n",
    "\n",
    "Take the work we did in the lessons further:\n",
    "\n",
    "**1. What other types of models (i.e. different classifcation algorithms) could you use? Create a model with a different algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "799b2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5).fit(X_train, y_train)\n",
    "train['tree_predicted'] = tree.predict(X_train)\n",
    "test['tree_predicted'] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cafba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.05%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual           ham  spam\n",
      "tree_predicted            \n",
      "ham             3834   151\n",
      "spam              25   447\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98      3859\n",
      "        spam       0.95      0.75      0.84       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.95      0.87      0.91      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.tree_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.tree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b6f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.71%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "tree_predicted           \n",
      "ham             950    43\n",
      "spam             16   106\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97       966\n",
      "        spam       0.87      0.71      0.78       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.91      0.85      0.88      1115\n",
      "weighted avg       0.94      0.95      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.tree_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.tree_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b30e5",
   "metadata": {},
   "source": [
    "**2. How do the models compare when trained on term frequency data alone, instead of TF-IDF values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c18a023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_bag_of_words = cv.fit_transform(df.text)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f03f392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d30e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000pes',\n",
       " '008704050406',\n",
       " '0089',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '0125698789',\n",
       " '02',\n",
       " '0207',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '021',\n",
       " '03',\n",
       " '04',\n",
       " '0430',\n",
       " '05',\n",
       " '050703',\n",
       " '0578',\n",
       " '06',\n",
       " '07',\n",
       " '07008009200',\n",
       " '07046744435',\n",
       " '07090201529',\n",
       " '07090298926',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '0721072',\n",
       " '07732584351',\n",
       " '07734396839',\n",
       " '07742676969',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07781482378',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '078',\n",
       " '07801543489',\n",
       " '07808',\n",
       " '07808247860',\n",
       " '07808726822',\n",
       " '07815296484',\n",
       " '07821230901',\n",
       " '078498',\n",
       " '07880867867',\n",
       " '0789xxxxxxx',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '08000407165',\n",
       " '08000776320',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08002988890',\n",
       " '08006344447',\n",
       " '0808',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0825',\n",
       " '083',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845',\n",
       " '08450542832',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075over18',\n",
       " '0870',\n",
       " '08700435505150p',\n",
       " '08700469649',\n",
       " '08700621170150p',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701417012150p',\n",
       " '0870141701216',\n",
       " '087016248',\n",
       " '08701752560',\n",
       " '087018728737',\n",
       " '0870241182716',\n",
       " '08702490080',\n",
       " '08702840625',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08704439680ts',\n",
       " '08706091795',\n",
       " '0870737910216yrs',\n",
       " '08707500020',\n",
       " '08707509020',\n",
       " '0870753331018',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '08709501522',\n",
       " '0871',\n",
       " '087104711148',\n",
       " '08712101358',\n",
       " '08712103738',\n",
       " '0871212025016',\n",
       " '08712300220',\n",
       " '087123002209am',\n",
       " '08712317606',\n",
       " '08712400200',\n",
       " '08712400602450p',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712402972',\n",
       " '08712404000',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '08712466669',\n",
       " '0871277810710p',\n",
       " '0871277810810',\n",
       " '0871277810910p',\n",
       " '08714342399',\n",
       " '087147123779am',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714712394',\n",
       " '08714712412',\n",
       " '08714714011',\n",
       " '08715203028',\n",
       " '08715203649',\n",
       " '08715203652',\n",
       " '08715203656',\n",
       " '08715203677',\n",
       " '08715203685',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '08717168528',\n",
       " '08717205546',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717509990',\n",
       " '08717890890',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718723815',\n",
       " '08718725756',\n",
       " '08718726270',\n",
       " '087187262701',\n",
       " '08718726970',\n",
       " '08718726971',\n",
       " '08718726978',\n",
       " '087187272008',\n",
       " '08718727868',\n",
       " '08718727870',\n",
       " '08718727870150ppm',\n",
       " '08718730555',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08718738034',\n",
       " '08719180219',\n",
       " '08719180248',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719181513',\n",
       " '08719839835',\n",
       " '08719899217',\n",
       " '08719899229',\n",
       " '08719899230',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000332',\n",
       " '09050000460',\n",
       " '09050000555',\n",
       " '09050000878',\n",
       " '09050000928',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050002311',\n",
       " '09050003091',\n",
       " '09050005321',\n",
       " '09050090044',\n",
       " '09050280520',\n",
       " '09053750005',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058091870',\n",
       " '09058094454',\n",
       " '09058094455',\n",
       " '09058094507',\n",
       " '09058094565',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058094599',\n",
       " '09058095107',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061701461',\n",
       " '09061701851',\n",
       " '09061701939',\n",
       " '09061702893',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061743811',\n",
       " '09061744553',\n",
       " '09061749602',\n",
       " '09061790121',\n",
       " '09061790125',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '0906346330',\n",
       " '09064011000',\n",
       " '09064012103',\n",
       " '09064012160',\n",
       " '09064015307',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09064019788',\n",
       " '09065069120',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065394514',\n",
       " '09065394973',\n",
       " '09065989180',\n",
       " '09065989182',\n",
       " '09066350750',\n",
       " '09066358152',\n",
       " '09066358361',\n",
       " '09066361921',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364349',\n",
       " '09066364589',\n",
       " '09066368327',\n",
       " '09066368470',\n",
       " '09066368753',\n",
       " '09066380611',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066649731from',\n",
       " '09066660100',\n",
       " '09071512432',\n",
       " '09071512433',\n",
       " '09071517866',\n",
       " '09077818151',\n",
       " '09090204448',\n",
       " '09090900040',\n",
       " '09094100151',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09095350301',\n",
       " '09096102316',\n",
       " '09099725823',\n",
       " '09099726395',\n",
       " '09099726429',\n",
       " '09099726481',\n",
       " '09099726553',\n",
       " '09111030116',\n",
       " '09111032124',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '0quit',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000call',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100percent',\n",
       " '100txt',\n",
       " '1013',\n",
       " '1030',\n",
       " '10am',\n",
       " '10k',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '10th',\n",
       " '11',\n",
       " '1120',\n",
       " '113',\n",
       " '1131',\n",
       " '114',\n",
       " '116',\n",
       " '1172',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '1205',\n",
       " '120p',\n",
       " '121',\n",
       " '1225',\n",
       " '123',\n",
       " '125',\n",
       " '1250',\n",
       " '125gift',\n",
       " '128',\n",
       " '12hours',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '13',\n",
       " '130',\n",
       " '1327',\n",
       " '139',\n",
       " '14',\n",
       " '140',\n",
       " '1405',\n",
       " '140ppm',\n",
       " '145',\n",
       " '1450',\n",
       " '146tf150p',\n",
       " '14tcr',\n",
       " '14thmarch',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmpobox10183bhamb64xe',\n",
       " '150ppmsg',\n",
       " '150pw',\n",
       " '151',\n",
       " '153',\n",
       " '15541',\n",
       " '15pm',\n",
       " '16',\n",
       " '165',\n",
       " '1680',\n",
       " '169',\n",
       " '177',\n",
       " '18',\n",
       " '180',\n",
       " '1843',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '195',\n",
       " '1956669',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1da',\n",
       " '1er',\n",
       " '1hr',\n",
       " '1im',\n",
       " '1lemon',\n",
       " '1mega',\n",
       " '1million',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice',\n",
       " '1stone',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '1yf',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '200p',\n",
       " '2025050',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21870000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '2309',\n",
       " '23f',\n",
       " '23g',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26',\n",
       " '2667',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '2814032',\n",
       " '28days',\n",
       " '28th',\n",
       " '28thfeb',\n",
       " '29',\n",
       " '2b',\n",
       " '2bold',\n",
       " '2c',\n",
       " '2channel',\n",
       " '2day',\n",
       " '2end',\n",
       " '2exit',\n",
       " '2ez',\n",
       " '2find',\n",
       " '2getha',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2gthr',\n",
       " '2hrs',\n",
       " '2kbsubject',\n",
       " '2lands',\n",
       " '2marrow',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mro',\n",
       " '2mrw',\n",
       " '2nd',\n",
       " '2nhite',\n",
       " '2nights',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2price',\n",
       " '2px',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2u',\n",
       " '2u2',\n",
       " '2waxsto',\n",
       " '2wks',\n",
       " '2wt',\n",
       " '2wu',\n",
       " '2years',\n",
       " '2yr',\n",
       " '2yrs',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300603t',\n",
       " '300p',\n",
       " '3030',\n",
       " '30apr',\n",
       " '30ish',\n",
       " '30pm',\n",
       " '30pp',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '3100',\n",
       " '310303',\n",
       " '31p',\n",
       " '32',\n",
       " '32000',\n",
       " '3230',\n",
       " '32323',\n",
       " '326',\n",
       " '33',\n",
       " '330',\n",
       " '350',\n",
       " '3510i',\n",
       " '35p',\n",
       " '3650',\n",
       " '36504',\n",
       " '3680',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '38',\n",
       " '382',\n",
       " '391784',\n",
       " '3aj',\n",
       " '3d',\n",
       " '3days',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lions',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3wks',\n",
       " '3xx',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '400thousad',\n",
       " '402',\n",
       " '4041',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '40mph',\n",
       " '41685',\n",
       " '41782',\n",
       " '420',\n",
       " '42049',\n",
       " '4217',\n",
       " '42478',\n",
       " '42810',\n",
       " '430',\n",
       " '434',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '44345',\n",
       " '447797706009',\n",
       " '447801259231',\n",
       " '448712404000',\n",
       " '449050000301',\n",
       " '449071512431',\n",
       " '45',\n",
       " '450',\n",
       " '450p',\n",
       " '450pw',\n",
       " '45239',\n",
       " '45pm',\n",
       " '47',\n",
       " '4719',\n",
       " '4742',\n",
       " '47per',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49',\n",
       " '49557',\n",
       " '4a',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4few',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4give',\n",
       " '4got',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4msgs',\n",
       " '4mths',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4the',\n",
       " '4thnov',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4utxt',\n",
       " '4w',\n",
       " '4ward',\n",
       " '4wrd',\n",
       " '4xx26',\n",
       " '4years',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '505060',\n",
       " '50award',\n",
       " '50ea',\n",
       " '50gbp',\n",
       " '50p',\n",
       " '50perweeksub',\n",
       " '50perwksub',\n",
       " '50pm',\n",
       " '50pmmorefrommobile2bremoved',\n",
       " '50ppm',\n",
       " '50rcvd',\n",
       " '50s',\n",
       " '515',\n",
       " '5226',\n",
       " '523',\n",
       " '526',\n",
       " '528',\n",
       " '530',\n",
       " '54',\n",
       " '542',\n",
       " '545',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5ish',\n",
       " '5k',\n",
       " '5min',\n",
       " '5mls',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '5wq',\n",
       " '5years',\n",
       " '60',\n",
       " '600',\n",
       " '6031',\n",
       " '6089',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '62220cncl',\n",
       " '6230',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '63miles',\n",
       " '645',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '6669',\n",
       " '674',\n",
       " '67441233',\n",
       " '68866',\n",
       " '69101',\n",
       " '69200',\n",
       " '69669',\n",
       " '69696',\n",
       " '69698',\n",
       " '69855',\n",
       " '69866',\n",
       " '69876',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '69969',\n",
       " '69988',\n",
       " '6days',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6times',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '700',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '730',\n",
       " '731',\n",
       " '74355',\n",
       " '75',\n",
       " '750',\n",
       " '7548',\n",
       " '75max',\n",
       " '762',\n",
       " '7634',\n",
       " '7684',\n",
       " '77',\n",
       " '7732584351',\n",
       " '78',\n",
       " '786',\n",
       " '7876150ppm',\n",
       " '79',\n",
       " '7am',\n",
       " '7cfca1a',\n",
       " '7ish',\n",
       " '7mp',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '7ws',\n",
       " '7zs',\n",
       " '80',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80086',\n",
       " '80122300p',\n",
       " '80155',\n",
       " '80160',\n",
       " '80182',\n",
       " '8027',\n",
       " '80488',\n",
       " '80608',\n",
       " '8077',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '81618',\n",
       " '82050',\n",
       " '820554ad0a1705572711',\n",
       " '82242',\n",
       " '82277',\n",
       " '82324',\n",
       " '82468',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83110',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332',\n",
       " '83338',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84',\n",
       " '84025',\n",
       " '84122',\n",
       " '84128',\n",
       " '84199',\n",
       " '84484',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '85069',\n",
       " '85222',\n",
       " '85233',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '864233',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '8714714',\n",
       " '872',\n",
       " '87239',\n",
       " '87575',\n",
       " '8800',\n",
       " '88039',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88877',\n",
       " '88888',\n",
       " '89034',\n",
       " '89070',\n",
       " '89080',\n",
       " '89105',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '89938',\n",
       " '8am',\n",
       " '8ball',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8wp',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9153',\n",
       " '9280114',\n",
       " '930',\n",
       " '9307622',\n",
       " '945',\n",
       " '946',\n",
       " '95',\n",
       " '9755',\n",
       " '9758',\n",
       " '97n7qp',\n",
       " '98321561',\n",
       " '99',\n",
       " '9996',\n",
       " '9ae',\n",
       " '9am',\n",
       " '9ja',\n",
       " '9pm',\n",
       " '9t',\n",
       " '9th',\n",
       " '9yt',\n",
       " '____',\n",
       " 'a21',\n",
       " 'a30',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aaniye',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'ab',\n",
       " 'abbey',\n",
       " 'abdomen',\n",
       " 'abeg',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'about',\n",
       " 'aboutas',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abuse',\n",
       " 'abusers',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accenture',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accidant',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodation',\n",
       " 'accommodationvouchers',\n",
       " 'accomodate',\n",
       " 'accomodations',\n",
       " 'accordin',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulation',\n",
       " 'achan',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'acid',\n",
       " 'acknowledgement',\n",
       " 'acl03530150pm',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activ8',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addie',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adewale',\n",
       " 'adi',\n",
       " 'adjustable',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'adore',\n",
       " 'adoring',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'adventuring',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advising',\n",
       " 'advisors',\n",
       " 'aeronautics',\n",
       " 'aeroplane',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affections',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterwards',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'age23',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'agidhane',\n",
       " 'aging',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aid',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'air1',\n",
       " 'airport',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd135b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 3550,\n",
       " 'until': 8030,\n",
       " 'jurong': 4350,\n",
       " 'point': 5920,\n",
       " 'crazy': 2327,\n",
       " 'available': 1303,\n",
       " 'only': 5537,\n",
       " 'in': 4087,\n",
       " 'bugis': 1751,\n",
       " 'great': 3634,\n",
       " 'world': 8489,\n",
       " 'la': 4476,\n",
       " 'buffet': 1749,\n",
       " 'cine': 2048,\n",
       " 'there': 7645,\n",
       " 'got': 3594,\n",
       " 'amore': 1069,\n",
       " 'wat': 8267,\n",
       " 'ok': 5504,\n",
       " 'lar': 4512,\n",
       " 'joking': 4318,\n",
       " 'wif': 8392,\n",
       " 'oni': 5533,\n",
       " 'free': 3358,\n",
       " 'entry': 2949,\n",
       " 'wkly': 8447,\n",
       " 'comp': 2165,\n",
       " 'to': 7756,\n",
       " 'win': 8405,\n",
       " 'fa': 3087,\n",
       " 'cup': 2386,\n",
       " 'final': 3207,\n",
       " 'tkts': 7743,\n",
       " '21st': 411,\n",
       " 'may': 4930,\n",
       " '2005': 402,\n",
       " 'text': 7595,\n",
       " '87121': 784,\n",
       " 'receive': 6297,\n",
       " 'question': 6190,\n",
       " 'std': 7230,\n",
       " 'txt': 7933,\n",
       " 'rate': 6242,\n",
       " 'apply': 1156,\n",
       " '08452810075over18': 77,\n",
       " 'dun': 2802,\n",
       " 'say': 6633,\n",
       " 'so': 7024,\n",
       " 'early': 2823,\n",
       " 'hor': 3927,\n",
       " 'already': 1042,\n",
       " 'then': 7640,\n",
       " 'nah': 5238,\n",
       " 'don': 2712,\n",
       " 'think': 7660,\n",
       " 'he': 3781,\n",
       " 'goes': 3558,\n",
       " 'usf': 8075,\n",
       " 'lives': 4665,\n",
       " 'around': 1207,\n",
       " 'here': 3831,\n",
       " 'though': 7680,\n",
       " 'freemsg': 3365,\n",
       " 'hey': 3841,\n",
       " 'darling': 2443,\n",
       " 'it': 4218,\n",
       " 'been': 1460,\n",
       " 'week': 8313,\n",
       " 'now': 5420,\n",
       " 'and': 1084,\n",
       " 'no': 5367,\n",
       " 'word': 8480,\n",
       " 'back': 1351,\n",
       " 'like': 4615,\n",
       " 'some': 7039,\n",
       " 'fun': 3419,\n",
       " 'you': 8609,\n",
       " 'up': 8032,\n",
       " 'for': 3308,\n",
       " 'still': 7253,\n",
       " 'tb': 7529,\n",
       " 'xxx': 8555,\n",
       " 'chgs': 2002,\n",
       " 'send': 6723,\n",
       " '50': 607,\n",
       " 'rcv': 6255,\n",
       " 'even': 2998,\n",
       " 'my': 5223,\n",
       " 'brother': 1722,\n",
       " 'is': 4206,\n",
       " 'not': 5405,\n",
       " 'speak': 7112,\n",
       " 'with': 8433,\n",
       " 'me': 4939,\n",
       " 'they': 7653,\n",
       " 'treat': 7863,\n",
       " 'aids': 992,\n",
       " 'patent': 5722,\n",
       " 'as': 1224,\n",
       " 'per': 5764,\n",
       " 'your': 8615,\n",
       " 'request': 6406,\n",
       " 'melle': 4969,\n",
       " 'oru': 5593,\n",
       " 'minnaminunginte': 5036,\n",
       " 'nurungu': 5440,\n",
       " 'vettam': 8131,\n",
       " 'has': 3757,\n",
       " 'set': 6750,\n",
       " 'callertune': 1823,\n",
       " 'all': 1029,\n",
       " 'callers': 1822,\n",
       " 'press': 6041,\n",
       " 'copy': 2266,\n",
       " 'friends': 3381,\n",
       " 'winner': 8416,\n",
       " 'valued': 8100,\n",
       " 'network': 5317,\n",
       " 'customer': 2399,\n",
       " 'have': 3770,\n",
       " 'selected': 6709,\n",
       " 'receivea': 6298,\n",
       " '900': 816,\n",
       " 'prize': 6073,\n",
       " 'reward': 6461,\n",
       " 'claim': 2054,\n",
       " 'call': 1813,\n",
       " '09061701461': 224,\n",
       " 'code': 2120,\n",
       " 'kl341': 4439,\n",
       " 'valid': 8096,\n",
       " '12': 322,\n",
       " 'hours': 3947,\n",
       " 'had': 3699,\n",
       " 'mobile': 5089,\n",
       " '11': 312,\n",
       " 'months': 5129,\n",
       " 'or': 5570,\n",
       " 'more': 5133,\n",
       " 'entitled': 2946,\n",
       " 'update': 8037,\n",
       " 'the': 7627,\n",
       " 'latest': 4526,\n",
       " 'colour': 2141,\n",
       " 'mobiles': 5090,\n",
       " 'camera': 1835,\n",
       " 'co': 2109,\n",
       " 'on': 5525,\n",
       " '08002986030': 61,\n",
       " 'gonna': 3574,\n",
       " 'be': 1438,\n",
       " 'home': 3901,\n",
       " 'soon': 7066,\n",
       " 'want': 8245,\n",
       " 'talk': 7496,\n",
       " 'about': 859,\n",
       " 'this': 7669,\n",
       " 'stuff': 7320,\n",
       " 'anymore': 1123,\n",
       " 'tonight': 7792,\n",
       " 've': 8115,\n",
       " 'cried': 2344,\n",
       " 'enough': 2936,\n",
       " 'today': 7763,\n",
       " 'six': 6928,\n",
       " 'chances': 1943,\n",
       " 'cash': 1889,\n",
       " 'from': 3397,\n",
       " '100': 298,\n",
       " '20': 397,\n",
       " '000': 1,\n",
       " 'pounds': 5982,\n",
       " 'csh11': 2363,\n",
       " '87575': 789,\n",
       " 'cost': 2278,\n",
       " '150p': 351,\n",
       " 'day': 2458,\n",
       " '6days': 680,\n",
       " '16': 363,\n",
       " 'tsandcs': 7898,\n",
       " 'reply': 6399,\n",
       " 'hl': 3873,\n",
       " 'info': 4122,\n",
       " 'urgent': 8055,\n",
       " 'won': 8464,\n",
       " 'membership': 4975,\n",
       " 'our': 5606,\n",
       " 'jackpot': 4247,\n",
       " '81010': 737,\n",
       " 'www': 8537,\n",
       " 'dbuk': 2463,\n",
       " 'net': 5311,\n",
       " 'lccltd': 4543,\n",
       " 'pobox': 5899,\n",
       " '4403ldnw1a7rw18': 559,\n",
       " 'searching': 6678,\n",
       " 'right': 6473,\n",
       " 'words': 8481,\n",
       " 'thank': 7612,\n",
       " 'breather': 1691,\n",
       " 'promise': 6105,\n",
       " 'wont': 8471,\n",
       " 'take': 7488,\n",
       " 'help': 3817,\n",
       " 'granted': 3623,\n",
       " 'will': 8402,\n",
       " 'fulfil': 3415,\n",
       " 'wonderful': 8468,\n",
       " 'blessing': 1567,\n",
       " 'at': 1260,\n",
       " 'times': 7722,\n",
       " 'date': 2451,\n",
       " 'sunday': 7388,\n",
       " 'xxxmobilemovieclub': 8556,\n",
       " 'use': 8069,\n",
       " 'credit': 2334,\n",
       " 'click': 2077,\n",
       " 'wap': 8250,\n",
       " 'link': 4637,\n",
       " 'next': 5334,\n",
       " 'message': 4993,\n",
       " 'http': 3968,\n",
       " 'com': 2144,\n",
       " 'qjkgighjjgcbl': 6182,\n",
       " 'oh': 5499,\n",
       " 'watching': 8272,\n",
       " 'eh': 2870,\n",
       " 'remember': 6366,\n",
       " 'how': 3953,\n",
       " 'spell': 7127,\n",
       " 'his': 3864,\n",
       " 'name': 5244,\n",
       " 'yes': 8592,\n",
       " 'did': 2592,\n",
       " 'naughty': 5271,\n",
       " 'make': 4848,\n",
       " 'wet': 8350,\n",
       " 'fine': 3215,\n",
       " 'if': 4041,\n",
       " 'thats': 7625,\n",
       " 'way': 8284,\n",
       " 'feel': 3158,\n",
       " 'its': 4225,\n",
       " 'gota': 3595,\n",
       " 'england': 2927,\n",
       " 'macedonia': 4810,\n",
       " 'dont': 2716,\n",
       " 'miss': 5052,\n",
       " 'goals': 3554,\n",
       " 'team': 7541,\n",
       " 'news': 5330,\n",
       " 'ur': 8051,\n",
       " 'national': 5265,\n",
       " '87077': 783,\n",
       " 'eg': 2865,\n",
       " 'try': 7894,\n",
       " 'wales': 8225,\n",
       " 'scotland': 6657,\n",
       " '4txt': 599,\n",
       " '1': 8659,\n",
       " 'poboxox36504w45wq': 5911,\n",
       " 'that': 7621,\n",
       " 'seriously': 6743,\n",
       " 'going': 3563,\n",
       " 'ha': 3695,\n",
       " '_': 8658,\n",
       " 'pay': 5734,\n",
       " 'first': 3232,\n",
       " 'when': 8362,\n",
       " 'da': 2416,\n",
       " 'stock': 7256,\n",
       " 'comin': 2155,\n",
       " 'aft': 962,\n",
       " 'finish': 3218,\n",
       " 'lunch': 4776,\n",
       " 'str': 7281,\n",
       " 'down': 2737,\n",
       " 'lor': 4719,\n",
       " 'ard': 1182,\n",
       " 'smth': 7007,\n",
       " 'ffffffffff': 3177,\n",
       " 'alright': 1043,\n",
       " 'can': 1839,\n",
       " 'meet': 4958,\n",
       " 'sooner': 7067,\n",
       " 'just': 4352,\n",
       " 'forced': 3310,\n",
       " 'myself': 5228,\n",
       " 'eat': 2835,\n",
       " 'slice': 6959,\n",
       " 'really': 6280,\n",
       " 'hungry': 3988,\n",
       " 'tho': 7676,\n",
       " 'sucks': 7357,\n",
       " 'mark': 4885,\n",
       " 'getting': 3511,\n",
       " 'worried': 8492,\n",
       " 'knows': 4450,\n",
       " 'sick': 6877,\n",
       " 'turn': 7917,\n",
       " 'pizza': 5854,\n",
       " 'lol': 4696,\n",
       " 'always': 1052,\n",
       " 'convincing': 2254,\n",
       " 'catch': 1899,\n",
       " 'bus': 1771,\n",
       " 'are': 1183,\n",
       " 'frying': 3403,\n",
       " 'an': 1079,\n",
       " 'egg': 2867,\n",
       " 'tea': 7535,\n",
       " 'eating': 2838,\n",
       " 'mom': 5110,\n",
       " 'left': 4566,\n",
       " 'over': 5627,\n",
       " 'dinner': 2624,\n",
       " 'do': 2675,\n",
       " 'love': 4740,\n",
       " 'amp': 1071,\n",
       " 'we': 8289,\n",
       " 're': 6259,\n",
       " 'packing': 5653,\n",
       " 'car': 1861,\n",
       " 'll': 4669,\n",
       " 'let': 4587,\n",
       " 'know': 4447,\n",
       " 'room': 6514,\n",
       " 'ahhh': 987,\n",
       " 'work': 8482,\n",
       " 'vaguely': 8092,\n",
       " 'what': 8355,\n",
       " 'does': 2687,\n",
       " 'wait': 8219,\n",
       " 'clear': 2071,\n",
       " 'were': 8339,\n",
       " 'sure': 7414,\n",
       " 'being': 1478,\n",
       " 'sarcastic': 6613,\n",
       " 'why': 8385,\n",
       " 'doesn': 2689,\n",
       " 'live': 4661,\n",
       " 'us': 8065,\n",
       " 'yeah': 8580,\n",
       " 'was': 8259,\n",
       " 'apologetic': 1143,\n",
       " 'fallen': 3112,\n",
       " 'out': 5609,\n",
       " 'she': 6795,\n",
       " 'actin': 904,\n",
       " 'spoilt': 7154,\n",
       " 'child': 2010,\n",
       " 'caught': 1903,\n",
       " 'till': 7719,\n",
       " 'but': 1778,\n",
       " 'doing': 2702,\n",
       " 'too': 7796,\n",
       " 'badly': 1356,\n",
       " 'cheers': 1986,\n",
       " 'tell': 7559,\n",
       " 'anything': 1129,\n",
       " 'fear': 3150,\n",
       " 'of': 5477,\n",
       " 'fainting': 3104,\n",
       " 'housework': 3951,\n",
       " 'quick': 6193,\n",
       " 'cuppa': 2388,\n",
       " 'thanks': 7613,\n",
       " 'subscription': 7345,\n",
       " 'ringtone': 6482,\n",
       " 'uk': 7963,\n",
       " 'charged': 1955,\n",
       " 'month': 5126,\n",
       " 'please': 5879,\n",
       " 'confirm': 2209,\n",
       " 'by': 1794,\n",
       " 'replying': 6400,\n",
       " 'yup': 8637,\n",
       " 'look': 4707,\n",
       " 'timings': 7726,\n",
       " 'msg': 5168,\n",
       " 'again': 970,\n",
       " 'xuhui': 8551,\n",
       " 'learn': 4556,\n",
       " '2nd': 461,\n",
       " 'her': 3830,\n",
       " 'lesson': 4585,\n",
       " '8am': 809,\n",
       " 'oops': 5548,\n",
       " 'roommate': 6516,\n",
       " 'done': 2714,\n",
       " 'see': 6695,\n",
       " 'letter': 4589,\n",
       " 'decide': 2481,\n",
       " 'hello': 3814,\n",
       " 'saturday': 6625,\n",
       " 'texting': 7603,\n",
       " 'decided': 2482,\n",
       " 'tomo': 7781,\n",
       " 'trying': 7896,\n",
       " 'invite': 4180,\n",
       " 'pls': 5887,\n",
       " 'ahead': 986,\n",
       " 'watts': 8280,\n",
       " 'wanted': 8247,\n",
       " 'weekend': 8315,\n",
       " 'abiola': 855,\n",
       " 'forget': 3316,\n",
       " 'need': 5291,\n",
       " 'crave': 2324,\n",
       " 'most': 5141,\n",
       " 'sweet': 7445,\n",
       " 'arabian': 1179,\n",
       " 'steed': 7237,\n",
       " 'mmmmmm': 5079,\n",
       " 'yummy': 8632,\n",
       " '07732584351': 30,\n",
       " 'rodger': 6504,\n",
       " 'burns': 1768,\n",
       " 'tried': 7872,\n",
       " 'sms': 7002,\n",
       " 'nokia': 5377,\n",
       " 'camcorder': 1833,\n",
       " '08000930705': 57,\n",
       " 'delivery': 2521,\n",
       " 'tomorrow': 7783,\n",
       " 'who': 8378,\n",
       " 'seeing': 6697,\n",
       " 'hope': 3919,\n",
       " 'man': 4858,\n",
       " 'well': 8330,\n",
       " 'endowed': 2917,\n",
       " 'am': 1054,\n",
       " 'lt': 4763,\n",
       " 'gt': 3663,\n",
       " 'inches': 4091,\n",
       " 'calls': 1828,\n",
       " 'messages': 4995,\n",
       " 'missed': 5054,\n",
       " 'didn': 2594,\n",
       " 'get': 3503,\n",
       " 'hep': 3829,\n",
       " 'immunisation': 4070,\n",
       " 'nigeria': 5344,\n",
       " 'fair': 3105,\n",
       " 'hopefully': 3922,\n",
       " 'tyler': 7946,\n",
       " 'could': 2289,\n",
       " 'maybe': 4932,\n",
       " 'ask': 1234,\n",
       " 'bit': 1544,\n",
       " 'stubborn': 7309,\n",
       " 'hospital': 3934,\n",
       " 'kept': 4396,\n",
       " 'telling': 7560,\n",
       " 'weak': 8290,\n",
       " 'sucker': 7355,\n",
       " 'hospitals': 3935,\n",
       " 'suckers': 7356,\n",
       " 'thinked': 7661,\n",
       " 'time': 7721,\n",
       " 'saw': 6632,\n",
       " 'class': 2063,\n",
       " 'gram': 3615,\n",
       " 'usually': 8081,\n",
       " 'runs': 6557,\n",
       " 'half': 3711,\n",
       " 'eighth': 2873,\n",
       " 'smarter': 6982,\n",
       " 'gets': 3507,\n",
       " 'almost': 1038,\n",
       " 'whole': 8379,\n",
       " 'second': 6682,\n",
       " 'fyi': 3435,\n",
       " 'ride': 6472,\n",
       " 'morning': 5137,\n",
       " 'crashing': 2323,\n",
       " 'place': 5856,\n",
       " 'wow': 8508,\n",
       " 'never': 5321,\n",
       " 'realized': 6278,\n",
       " 'embarassed': 2898,\n",
       " 'accomodations': 886,\n",
       " 'thought': 7681,\n",
       " 'liked': 4616,\n",
       " 'since': 6902,\n",
       " 'best': 1498,\n",
       " 'seemed': 6701,\n",
       " 'happy': 3746,\n",
       " 'cave': 1907,\n",
       " 'sorry': 7076,\n",
       " 'give': 3532,\n",
       " 'offered': 5484,\n",
       " 'embarassing': 2899,\n",
       " 'ac': 872,\n",
       " 'sptv': 7176,\n",
       " 'new': 5325,\n",
       " 'jersey': 4288,\n",
       " 'devils': 2573,\n",
       " 'detroit': 2567,\n",
       " 'red': 6320,\n",
       " 'wings': 8414,\n",
       " 'play': 5870,\n",
       " 'ice': 4022,\n",
       " 'hockey': 3886,\n",
       " 'correct': 2271,\n",
       " 'incorrect': 4102,\n",
       " 'end': 2913,\n",
       " 'mallika': 4857,\n",
       " 'sherawat': 6802,\n",
       " 'yesterday': 8594,\n",
       " 'find': 3212,\n",
       " 'url': 8061,\n",
       " 'congrats': 2215,\n",
       " 'year': 8581,\n",
       " 'special': 7114,\n",
       " 'cinema': 2049,\n",
       " 'pass': 5711,\n",
       " 'yours': 8619,\n",
       " '09061209465': 219,\n",
       " 'suprman': 7412,\n",
       " 'matrix3': 4918,\n",
       " 'starwars3': 7218,\n",
       " 'etc': 2986,\n",
       " 'bx420': 1792,\n",
       " 'ip4': 4189,\n",
       " '5we': 641,\n",
       " '150pm': 353,\n",
       " 'later': 4525,\n",
       " 'meeting': 4960,\n",
       " 'where': 8366,\n",
       " 'reached': 6262,\n",
       " 'gauti': 3469,\n",
       " 'sehwag': 6706,\n",
       " 'odi': 5476,\n",
       " 'series': 6741,\n",
       " 'pick': 5826,\n",
       " 'burger': 1763,\n",
       " 'yourself': 8620,\n",
       " 'move': 5154,\n",
       " 'pain': 5660,\n",
       " 'killing': 4421,\n",
       " 'good': 3576,\n",
       " 'joke': 4314,\n",
       " 'girls': 3529,\n",
       " 'situation': 6925,\n",
       " 'seekers': 6698,\n",
       " 'part': 5700,\n",
       " 'checking': 1980,\n",
       " 'iq': 4195,\n",
       " 'roommates': 6517,\n",
       " 'took': 7797,\n",
       " 'forever': 3313,\n",
       " 'come': 2150,\n",
       " 'double': 2730,\n",
       " 'check': 1976,\n",
       " 'hair': 3706,\n",
       " 'dresser': 2760,\n",
       " 'said': 6583,\n",
       " 'wun': 8536,\n",
       " 'cut': 2403,\n",
       " 'short': 6837,\n",
       " 'nice': 5338,\n",
       " 'pleased': 5880,\n",
       " 'advise': 945,\n",
       " 'following': 3291,\n",
       " 'recent': 6301,\n",
       " 'review': 6459,\n",
       " 'mob': 5087,\n",
       " 'awarded': 1320,\n",
       " '1500': 350,\n",
       " 'bonus': 1608,\n",
       " '09066364589': 267,\n",
       " 'song': 7061,\n",
       " 'dedicated': 2492,\n",
       " 'which': 8372,\n",
       " 'dedicate': 2491,\n",
       " 'valuable': 8098,\n",
       " 'frnds': 3389,\n",
       " 'rply': 6533,\n",
       " 'complimentary': 2184,\n",
       " 'trip': 7873,\n",
       " 'eurodisinc': 2992,\n",
       " 'trav': 7855,\n",
       " 'aco': 900,\n",
       " 'entry41': 2950,\n",
       " '1000': 299,\n",
       " 'dis': 2636,\n",
       " '18': 368,\n",
       " 'morefrmmob': 5134,\n",
       " 'shracomorsglsuplt': 6862,\n",
       " '10': 297,\n",
       " 'ls1': 4759,\n",
       " '3aj': 518,\n",
       " 'hear': 3793,\n",
       " 'divorce': 2665,\n",
       " 'barbie': 1387,\n",
       " 'comes': 2152,\n",
       " 'ken': 4394,\n",
       " 'plane': 5862,\n",
       " 'wah': 8212,\n",
       " 'lucky': 4770,\n",
       " 'save': 6628,\n",
       " 'money': 5117,\n",
       " 'hee': 3806,\n",
       " 'finished': 3220,\n",
       " 'hi': 3846,\n",
       " 'babe': 1342,\n",
       " 'im': 4058,\n",
       " 'wanna': 8243,\n",
       " 'something': 7049,\n",
       " 'xx': 8552,\n",
       " 'performed': 5771,\n",
       " 'waiting': 8222,\n",
       " 'machan': 4812,\n",
       " 'once': 5529,\n",
       " 'thats': 7624,\n",
       " 'cool': 2259,\n",
       " 'gentleman': 3494,\n",
       " 'dignity': 2614,\n",
       " 'respect': 6426,\n",
       " 'peoples': 5763,\n",
       " 'very': 8130,\n",
       " 'much': 5186,\n",
       " 'shy': 6872,\n",
       " 'pa': 5649,\n",
       " 'operate': 5555,\n",
       " 'after': 963,\n",
       " 'same': 6598,\n",
       " 'looking': 4711,\n",
       " 'job': 4303,\n",
       " 'ta': 7473,\n",
       " 'earn': 2824,\n",
       " 'ah': 984,\n",
       " 'stop': 7266,\n",
       " 'urgnt': 8058,\n",
       " 'real': 6271,\n",
       " 'yo': 8604,\n",
       " 'tickets': 7709,\n",
       " 'one': 5531,\n",
       " 'jacket': 4246,\n",
       " 'used': 8070,\n",
       " 'multis': 5195,\n",
       " 'started': 7213,\n",
       " 'requests': 6407,\n",
       " 'came': 1834,\n",
       " 'bed': 1455,\n",
       " 'coins': 2126,\n",
       " 'factory': 3094,\n",
       " 'gotta': 3600,\n",
       " 'nitros': 5362,\n",
       " 'ela': 2878,\n",
       " 'kano': 4375,\n",
       " 'il': 4053,\n",
       " 'download': 2738,\n",
       " 'wen': 8333,\n",
       " 'stand': 7201,\n",
       " 'close': 2084,\n",
       " 'another': 1106,\n",
       " 'night': 5346,\n",
       " 'spent': 7132,\n",
       " 'late': 4522,\n",
       " 'afternoon': 965,\n",
       " 'casualty': 1897,\n",
       " 'means': 4946,\n",
       " 'haven': 3771,\n",
       " 'any': 1120,\n",
       " 'stuff42moro': 7321,\n",
       " 'includes': 4095,\n",
       " 'sheets': 6797,\n",
       " 'smile': 6990,\n",
       " 'pleasure': 5882,\n",
       " 'trouble': 7880,\n",
       " 'pours': 5984,\n",
       " 'rain': 6216,\n",
       " 'sum1': 7379,\n",
       " 'hurts': 3998,\n",
       " 'becoz': 1453,\n",
       " 'someone': 7043,\n",
       " 'loves': 4748,\n",
       " 'smiling': 6994,\n",
       " 'service': 6746,\n",
       " 'representative': 6404,\n",
       " '0800': 53,\n",
       " '169': 366,\n",
       " '6031': 647,\n",
       " 'between': 1507,\n",
       " '10am': 307,\n",
       " '9pm': 835,\n",
       " 'guaranteed': 3666,\n",
       " '5000': 609,\n",
       " 'havent': 3772,\n",
       " 'planning': 5866,\n",
       " 'buy': 1783,\n",
       " 'lido': 4600,\n",
       " '530': 627,\n",
       " 'show': 6853,\n",
       " 'collected': 2135,\n",
       " 'simply': 6899,\n",
       " 'password': 5718,\n",
       " 'mix': 5070,\n",
       " '85069': 770,\n",
       " 'verify': 8126,\n",
       " 'usher': 8076,\n",
       " 'britney': 1712,\n",
       " 'fml': 3282,\n",
       " 'telugu': 7565,\n",
       " 'movie': 5157,\n",
       " 'abt': 867,\n",
       " 'loads': 4675,\n",
       " 'loans': 4677,\n",
       " 'wk': 8443,\n",
       " 'hols': 3899,\n",
       " 'run': 6555,\n",
       " 'forgot': 3321,\n",
       " 'hairdressers': 3708,\n",
       " 'appointment': 1159,\n",
       " 'four': 3339,\n",
       " 'shower': 6855,\n",
       " 'beforehand': 1467,\n",
       " 'cause': 1904,\n",
       " 'prob': 6078,\n",
       " 'ham': 3717,\n",
       " 'nothing': 5410,\n",
       " 'else': 2892,\n",
       " 'okay': 5505,\n",
       " 'price': 6054,\n",
       " 'long': 4703,\n",
       " 'legal': 4569,\n",
       " 'them': 7636,\n",
       " 'ave': 1307,\n",
       " 'ams': 1075,\n",
       " 'gone': 3572,\n",
       " '4the': 597,\n",
       " 'driving': 2769,\n",
       " 'test': 7589,\n",
       " 'yet': 8595,\n",
       " 'mean': 4942,\n",
       " 'guess': 3672,\n",
       " 'gave': 3470,\n",
       " 'boston': 1629,\n",
       " 'men': 4979,\n",
       " 'changed': 1945,\n",
       " 'search': 6677,\n",
       " 'location': 4680,\n",
       " 'nyc': 5451,\n",
       " 'cuz': 2410,\n",
       " 'signin': 6887,\n",
       " 'page': 5656,\n",
       " 'says': 6636,\n",
       " 'umma': 7970,\n",
       " 'life': 4603,\n",
       " 'vava': 8112,\n",
       " 'lot': 4727,\n",
       " 'dear': 2471,\n",
       " 'wishes': 8427,\n",
       " 'birthday': 1542,\n",
       " 'making': 4852,\n",
       " 'truly': 7889,\n",
       " 'memorable': 4976,\n",
       " 'aight': 994,\n",
       " 'hit': 3866,\n",
       " 'would': 8504,\n",
       " 'ip': 4188,\n",
       " 'address': 922,\n",
       " 'considering': 2227,\n",
       " 'computer': 2190,\n",
       " 'isn': 4213,\n",
       " 'minecraft': 5030,\n",
       " 'server': 6745,\n",
       " 'grumpy': 3660,\n",
       " 'old': 5517,\n",
       " 'people': 5762,\n",
       " 'better': 1504,\n",
       " 'lying': 4790,\n",
       " 'jokes': 4316,\n",
       " 'worry': 8494,\n",
       " 'busy': 1777,\n",
       " 'plural': 5891,\n",
       " 'noun': 5417,\n",
       " 'research': 6412,\n",
       " 'cos': 2276,\n",
       " 'things': 7659,\n",
       " 'scared': 6642,\n",
       " 'mah': 4835,\n",
       " 'loud': 4735,\n",
       " 'gent': 3492,\n",
       " 'contact': 2232,\n",
       " 'last': 4519,\n",
       " 'weekends': 8316,\n",
       " 'draw': 2752,\n",
       " 'shows': 6861,\n",
       " '09064012160': 243,\n",
       " 'k52': 4358,\n",
       " '12hrs': 333,\n",
       " '150ppm': 355,\n",
       " 'wa': 8207,\n",
       " 'openin': 5552,\n",
       " 'sentence': 6734,\n",
       " 'formal': 3325,\n",
       " 'anyway': 1132,\n",
       " 'juz': 4357,\n",
       " 'tt': 7904,\n",
       " 'eatin': 2837,\n",
       " 'puttin': 6171,\n",
       " 'weight': 8321,\n",
       " 'haha': 3702,\n",
       " 'anythin': 1128,\n",
       " 'happened': 3738,\n",
       " 'entered': 2939,\n",
       " 'cabin': 1801,\n",
       " 'boss': 1628,\n",
       " 'felt': 3167,\n",
       " 'askd': 1235,\n",
       " 'invited': 4181,\n",
       " 'apartment': 1137,\n",
       " 'went': 8336,\n",
       " 'specially': 7118,\n",
       " 'holiday': 3896,\n",
       " 'flights': 3258,\n",
       " 'inc': 4089,\n",
       " 'operator': 5556,\n",
       " '0871277810910p': 129,\n",
       " 'min': 5023,\n",
       " 'goodo': 3585,\n",
       " 'must': 5214,\n",
       " 'friday': 3376,\n",
       " 'potato': 5976,\n",
       " 'ratio': 6245,\n",
       " 'tortilla': 7814,\n",
       " 'needed': 5293,\n",
       " 'hmm': 3878,\n",
       " 'uncle': 7979,\n",
       " 'informed': 4125,\n",
       " 'paying': 5739,\n",
       " 'school': 6648,\n",
       " 'directly': 2630,\n",
       " 'food': 3298,\n",
       " 'private': 6070,\n",
       " '2004': 401,\n",
       " 'account': 889,\n",
       " 'statement': 7221,\n",
       " '07742676969': 32,\n",
       " '786': 709,\n",
       " 'unredeemed': 8023,\n",
       " 'points': 5921,\n",
       " '08719180248': 175,\n",
       " 'identifier': 4034,\n",
       " '45239': 570,\n",
       " 'expires': 3065,\n",
       " '2000': 399,\n",
       " 'caller': 1821,\n",
       " '03': 15,\n",
       " 'landline': 4499,\n",
       " '09064019788': 249,\n",
       " 'box42wr29c': 1655,\n",
       " 'apples': 1154,\n",
       " 'pairs': 5664,\n",
       " 'malarky': 4854,\n",
       " 'todays': 7764,\n",
       " 'voda': 8176,\n",
       " 'numbers': 5437,\n",
       " 'ending': 2915,\n",
       " '7548': 701,\n",
       " '350': 506,\n",
       " 'award': 1319,\n",
       " 'match': 4906,\n",
       " '08712300220': 111,\n",
       " 'quoting': 6204,\n",
       " '4041': 543,\n",
       " 'standard': 7202,\n",
       " 'rates': 6243,\n",
       " 'app': 1147,\n",
       " 'sao': 6607,\n",
       " 'mu': 5184,\n",
       " '': 8661,\n",
       " 'predict': 6016,\n",
       " 'buying': 1786,\n",
       " 'yetunde': 8597,\n",
       " 'hasn': 3759,\n",
       " 'sent': 6733,\n",
       " 'bother': 1632,\n",
       " 'sending': 6725,\n",
       " 'involve': 4185,\n",
       " 'shouldn': 6848,\n",
       " 'imposed': 4077,\n",
       " 'apologise': 1144,\n",
       " 'girl': 3526,\n",
       " 'del': 2511,\n",
       " 'bak': 1364,\n",
       " 'sum': 7378,\n",
       " 'lucyxx': 4773,\n",
       " 'tmorrow': 7749,\n",
       " 'accomodate': 885,\n",
       " 'answer': 1109,\n",
       " 'sunshine': 7395,\n",
       " 'quiz': 6200,\n",
       " 'top': 7805,\n",
       " 'sony': 7063,\n",
       " 'dvd': 2812,\n",
       " 'player': 5872,\n",
       " 'country': 2296,\n",
       " 'algarve': 1022,\n",
       " 'ansr': 1108,\n",
       " '82277': 744,\n",
       " 'sp': 7099,\n",
       " 'tyrone': 7950,\n",
       " 'laid': 4491,\n",
       " 'dogging': 2696,\n",
       " 'locations': 4681,\n",
       " 'direct': 2629,\n",
       " 'join': 4311,\n",
       " 'largest': 4516,\n",
       " 'bt': 1738,\n",
       " 'txting': 7939,\n",
       " 'gravel': 3628,\n",
       " '69888': 675,\n",
       " 'nt': 5427,\n",
       " 'ec2a': 2840,\n",
       " '31p': 498,\n",
       " 'haf': 3701,\n",
       " 'msn': 5175,\n",
       " 'yijue': 8601,\n",
       " 'hotmail': 3942,\n",
       " 'him': 3857,\n",
       " 'rooms': 6518,\n",
       " 'befor': 1465,\n",
       " 'activities': 910,\n",
       " 'msgs': 5174,\n",
       " 'chat': 1966,\n",
       " 'svc': 7430,\n",
       " 'hardcore': 3748,\n",
       " 'services': 6747,\n",
       " '69988': 679,\n",
       " 'age': 973,\n",
       " 'yr': 8627,\n",
       " 'lazy': 4542,\n",
       " 'type': 7947,\n",
       " 'lect': 4563,\n",
       " 'pouch': 5979,\n",
       " 'sir': 6914,\n",
       " 'mail': 4840,\n",
       " 'swt': 7459,\n",
       " 'nver': 5445,\n",
       " 'tired': 7729,\n",
       " 'little': 4660,\n",
       " 'lovable': 4739,\n",
       " 'persons': 5789,\n",
       " 'coz': 2309,\n",
       " 'somtimes': 7058,\n",
       " 'those': 7677,\n",
       " 'occupy': 5469,\n",
       " 'biggest': 1524,\n",
       " 'their': 7633,\n",
       " 'hearts': 3799,\n",
       " 'gud': 3668,\n",
       " 'ni8': 5336,\n",
       " 'open': 5549,\n",
       " 'ya': 8565,\n",
       " 'dot': 2729,\n",
       " 'whats': 8357,\n",
       " 'staff': 7193,\n",
       " 'taking': 7493,\n",
       " 'replied': 6397,\n",
       " 'randy': 6236,\n",
       " 'sexy': 6763,\n",
       " 'female': 3168,\n",
       " 'local': 4679,\n",
       " 'luv': 4781,\n",
       " 'netcollex': 5312,\n",
       " 'ltd': 4764,\n",
       " '08700621170150p': 81,\n",
       " 'ummma': 7972,\n",
       " 'begin': 1471,\n",
       " 'qatar': 6177,\n",
       " 'pray': 6011,\n",
       " 'hard': 3747,\n",
       " 'deleted': 2515,\n",
       " 'sindu': 6904,\n",
       " 'birla': 1538,\n",
       " 'soft': 7029,\n",
       " 'wine': 8412,\n",
       " 'flowing': 3273,\n",
       " 'nevering': 5322,\n",
       " 'thk': 7670,\n",
       " 'plaza': 5877,\n",
       " 'typical': 7949,\n",
       " 'everywhere': 3016,\n",
       " 'dirt': 2633,\n",
       " 'floor': 3267,\n",
       " 'windows': 8409,\n",
       " 'shirt': 6816,\n",
       " 'sometimes': 7051,\n",
       " 'mouth': 5153,\n",
       " 'dream': 2755,\n",
       " 'without': 8437,\n",
       " 'chores': 2037,\n",
       " 'joy': 4329,\n",
       " 'lots': 4729,\n",
       " 'tv': 7922,\n",
       " 'exist': 3050,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the column location of each word\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1edb67e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>_</th>\n",
       "      <th>_</th>\n",
       "      <th>_thanks</th>\n",
       "      <th>m</th>\n",
       "      <th>t</th>\n",
       "      <th>ve</th>\n",
       "      <th></th>\n",
       "      <th>harry</th>\n",
       "      <th></th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows  8672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0      0    0       0             0     0     0            0            0   \n",
       "1      0    0       0             0     0     0            0            0   \n",
       "2      0    0       0             0     0     0            0            0   \n",
       "3      0    0       0             0     0     0            0            0   \n",
       "4      0    0       0             0     0     0            0            0   \n",
       "...   ..  ...     ...           ...   ...   ...          ...          ...   \n",
       "5567   0    0       0             0     0     0            0            0   \n",
       "5568   0    0       0             0     0     0            0            0   \n",
       "5569   0    0       0             0     0     0            0            0   \n",
       "5570   0    0       0             0     0     0            0            0   \n",
       "5571   0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  _  _  _thanks  m  t  ve    harry    \\\n",
       "0              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "1              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "2              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "3              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "4              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "...          ...  ..  ...  ..  ..       ...  ...  ...   ...  ..      ...  ..   \n",
       "5567           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5568           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5569           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5570           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5571           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "\n",
       "      well  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "5567       0  \n",
       "5568       0  \n",
       "5569       0  \n",
       "5570       0  \n",
       "5571       0  \n",
       "\n",
       "[5572 rows x 8672 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = pd.DataFrame(X_bag_of_words.todense(), columns=cv.get_feature_names())\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c05dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb430f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.55%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   107\n",
      "spam          2   491\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.98      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7be7c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.32%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        963    38\n",
      "spam         3   111\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.97      0.74      0.84       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.97      0.87      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36095e26",
   "metadata": {},
   "source": [
    "**Bonus: Can we use n-grams as a feature engineering method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54efbfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                Will _ b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: text, Length: 5572, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00 in</th>\n",
       "      <th>00 per</th>\n",
       "      <th>00 sub</th>\n",
       "      <th>00 subs</th>\n",
       "      <th>000 bonus</th>\n",
       "      <th>000 cash</th>\n",
       "      <th>000 homeowners</th>\n",
       "      <th>000 pounds</th>\n",
       "      <th>000 price</th>\n",
       "      <th>000 prize</th>\n",
       "      <th>...</th>\n",
       "      <th> am</th>\n",
       "      <th> even</th>\n",
       "      <th> favour</th>\n",
       "      <th> hope</th>\n",
       "      <th> indeed</th>\n",
       "      <th> is</th>\n",
       "      <th> sound</th>\n",
       "      <th> to</th>\n",
       "      <th> very</th>\n",
       "      <th>well done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows  41654 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00 in  00 per  00 sub  00 subs  000 bonus  000 cash  000 homeowners  \\\n",
       "0         0       0       0        0          0         0               0   \n",
       "1         0       0       0        0          0         0               0   \n",
       "2         0       0       0        0          0         0               0   \n",
       "3         0       0       0        0          0         0               0   \n",
       "4         0       0       0        0          0         0               0   \n",
       "...     ...     ...     ...      ...        ...       ...             ...   \n",
       "5567      0       0       0        0          0         0               0   \n",
       "5568      0       0       0        0          0         0               0   \n",
       "5569      0       0       0        0          0         0               0   \n",
       "5570      0       0       0        0          0         0               0   \n",
       "5571      0       0       0        0          0         0               0   \n",
       "\n",
       "      000 pounds  000 price  000 prize  ...   am   even   favour  \\\n",
       "0              0          0          0  ...      0        0          0   \n",
       "1              0          0          0  ...      0        0          0   \n",
       "2              0          0          0  ...      0        0          0   \n",
       "3              0          0          0  ...      0        0          0   \n",
       "4              0          0          0  ...      0        0          0   \n",
       "...          ...        ...        ...  ...    ...      ...        ...   \n",
       "5567           0          0          0  ...      0        0          0   \n",
       "5568           0          0          0  ...      0        0          0   \n",
       "5569           0          0          0  ...      0        0          0   \n",
       "5570           0          0          0  ...      0        0          0   \n",
       "5571           0          0          0  ...      0        0          0   \n",
       "\n",
       "       hope   indeed   is   sound   to   very  well done  \n",
       "0           0          0      0         0      0        0            0  \n",
       "1           0          0      0         0      0        0            0  \n",
       "2           0          0      0         0      0        0            0  \n",
       "3           0          0      0         0      0        0            0  \n",
       "4           0          0      0         0      0        0            0  \n",
       "...       ...        ...    ...       ...    ...      ...          ...  \n",
       "5567        0          0      0         0      0        0            0  \n",
       "5568        0          0      0         0      0        0            0  \n",
       "5569        0          0      0         0      0        0            0  \n",
       "5570        0          0      0         0      0        0            0  \n",
       "5571        0          0      0         0      0        0            0  \n",
       "\n",
       "[5572 rows x 41654 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "bigrams = cv.fit_transform(df.text)\n",
    "\n",
    "pprint(df.text)\n",
    "pd.DataFrame(bigrams.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e261cf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    0\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: go until, Length: 5572, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bigrams.todense(), columns=cv.get_feature_names())['go until']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9945083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bigrams.todense(), columns=cv.get_feature_names())['go until'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
